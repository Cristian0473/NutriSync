# 1.2.2. Seleccionar el algoritmo de Machine Learning más adecuado para el sistema de recomendación nutricional

## Demostración del cumplimiento del objetivo 2

La selección del algoritmo de Machine Learning se realizó mediante análisis comparativo de múltiples algoritmos candidatos, evaluación de sus características técnicas y aplicación de criterios específicos al contexto de recomendaciones nutricionales para diabetes tipo 2.

## Proceso de selección

Identificación de algoritmos candidatos: Se identificaron seis algoritmos candidatos mediante revisión bibliográfica de algoritmos comúnmente utilizados en sistemas de recomendación y salud digital: Regresión logística, KNN (k-Nearest Neighbors), SVM (Support Vector Machine), Árbol de decisión, Random Forest, XGBoost (Extreme Gradient Boosting).

Análisis de características de datos: Se analizaron características de los datos disponibles: Valores clínicos cuantitativos (HbA1c, glucosa, IMC, etc.) que requieren algoritmos capaces de manejar variables continuas. Variables categóricas (sexo, actividad) que requieren algoritmos capaces de manejar variables discretas. Atributos nutricionales de ingredientes (kcal, CHO, PRO, FAT) que requieren algoritmos capaces de manejar múltiples features numéricas. Datos tabulares (no imágenes ni texto) que favorecen algoritmos diseñados para datos estructurados.

Evaluación comparativa: Se evaluaron algoritmos según siete criterios clave: Precisión esperada (capacidad de hacer predicciones correctas), Interpretabilidad (facilidad de explicar decisiones), Manejo de datos heterogéneos (capacidad con numéricos, categóricos y JSON), Escalabilidad (rendimiento con grandes volúmenes de datos), Rendimiento computacional (tiempo y recursos necesarios), Aplicabilidad clínica (adopción en sistemas de salud), Compatibilidad con ecosistema Python/Postgres (facilidad de integración).

## Resultado de la evaluación

Regresión logística: Precisión media, buena en problemas lineales. Interpretabilidad muy alta mediante coeficientes claros. Manejo de datos heterogéneos limitado, requiere codificación manual. Escalabilidad excelente, muy rápido. Rendimiento computacional muy bajo costo. Aplicabilidad clínica buena como baseline explicable. Compatibilidad muy alta con sklearn. Decisión: No seleccionado como algoritmo principal debido a limitaciones en manejo de interacciones no lineales entre variables clínicas y nutricionales.

KNN: Precisión media, sensible al número de vecinos y ruido. Interpretabilidad baja, difícil interpretar vecinos. Manejo de datos heterogéneos limitado, necesita escalado. Escalabilidad mala en grandes volúmenes. Rendimiento computacional alto costo. Aplicabilidad clínica poca adopción por opacidad. Compatibilidad alta con sklearn. Decisión: No seleccionado debido a baja interpretabilidad y pobre escalabilidad.

SVM: Precisión alta en datasets pequeños/limpios. Interpretabilidad media-baja dependiendo de kernel. Manejo de datos heterogéneos limitado, necesita normalización rigurosa. Escalabilidad costosa en alta dimensionalidad. Rendimiento computacional alto, sensible a hiperparámetros. Aplicabilidad clínica limitada por complejidad. Compatibilidad alta con sklearn. Decisión: No seleccionado debido a complejidad de ajuste y limitada aplicabilidad clínica.

Árbol de decisión: Precisión media, tiende a sobreajustar. Interpretabilidad alta mediante reglas claras. Manejo de datos heterogéneos bueno, acepta variables mixtas. Escalabilidad buena pero se degrada con complejidad. Rendimiento computacional bajo, rápido. Aplicabilidad clínica útil para reglas clínicas simples. Compatibilidad muy alta con sklearn. Decisión: No seleccionado como algoritmo principal debido a tendencia a sobreajuste, pero útil como componente de Random Forest.

Random Forest: Precisión alta, robusto con ruido y complejidad. Interpretabilidad media mediante feature importance. Manejo de datos heterogéneos muy bueno, maneja datos mixtos. Escalabilidad buena, paralelizable. Rendimiento computacional moderado. Aplicabilidad clínica muy buena, balancea precisión e interpretabilidad. Compatibilidad muy alta con sklearn. Decisión: Seleccionado como modelo de referencia por robustez e interpretabilidad parcial.

XGBoost: Precisión muy alta, líder en tabulares. Interpretabilidad baja-media, requiere SHAP/LIME. Manejo de datos heterogéneos excelente, captura interacciones complejas. Escalabilidad excelente, optimizado para grandes volúmenes. Rendimiento computacional alto, requiere mayor tiempo de entrenamiento. Aplicabilidad clínica excelente, altamente competitivo en salud digital. Compatibilidad muy alta con xgboost y sklearn API. Decisión: Seleccionado como modelo principal por mayor capacidad predictiva.

## Decisión final

Se adoptó un enfoque híbrido utilizando Random Forest y XGBoost de manera complementaria.

Random Forest como modelo de referencia: Se utiliza para proporcionar predicciones robustas y explicables mediante importancia de variables. Permite identificar qué características clínicas (ej: HbA1c, IMC) son más influyentes en las predicciones. Proporciona validación cruzada de resultados de XGBoost mediante comparación de predicciones.

XGBoost como modelo principal: Se utiliza para recomendaciones finales debido a mayor precisión en contextos clínicos con múltiples variables interrelacionadas. Permite ajustes finos mediante validación cruzada y tuning de hiperparámetros. Se beneficia del volumen progresivo de datos que la aplicación recolectará mediante aprendizaje continuo.

## Implementación técnica

Modelo 1: Predicción de Respuesta Glucémica: Se implementa mediante XGBoost Regressor que predice múltiples targets: glucose_increment (incremento de glucosa), glucose_peak (pico de glucosa), time_to_peak (tiempo hasta pico). Se entrena con datos de NHANES que incluyen perfiles de pacientes y características de alimentos. Se utiliza para excluir alimentos que causarían picos glucémicos excesivos (mayor a 180 mg/dL).

Modelo 2: Selección Personalizada de Alimentos: Se implementa mediante XGBoost Classifier que clasifica alimentos como adecuados o no adecuados para un paciente específico. Se entrena con datos que incluyen perfiles de pacientes, características de alimentos y scores de idoneidad calculados. Se utiliza para rankear alimentos por idoneidad antes de la selección.

Modelo 3: Optimización de Combinaciones: Se implementa mediante Ensemble (XGBoost más Random Forest) que predice score de calidad de combinaciones de alimentos. Se entrena con datos que incluyen combinaciones de alimentos y scores de calidad calculados. Se utiliza durante la optimización para validar que combinaciones sugeridas tengan calidad adecuada.

## Justificación de la selección

Precisión: XGBoost ha demostrado consistentemente mayor precisión que otros algoritmos en competencias de machine learning con datos tabulares, especialmente en dominios de salud. Random Forest proporciona robustez adicional mediante promediado de múltiples árboles.

Interpretabilidad: Aunque XGBoost tiene menor interpretabilidad que regresión logística, Random Forest proporciona importancia de variables que permite explicar decisiones. Se puede utilizar SHAP (SHapley Additive exPlanations) para explicar predicciones individuales de XGBoost cuando sea necesario.

Manejo de datos heterogéneos: Ambos algoritmos manejan eficientemente mezclas de variables numéricas y categóricas sin requerir codificación manual extensiva. XGBoost maneja automáticamente valores faltantes mediante algoritmos de imputación integrados.

Escalabilidad: XGBoost está optimizado para grandes volúmenes de datos mediante paralelización y optimizaciones de memoria. Random Forest también es paralelizable mediante múltiples workers.

Aplicabilidad clínica: Ambos algoritmos han sido ampliamente adoptados en sistemas de salud digital, proporcionando confianza en su uso clínico. La combinación de ambos proporciona balance entre precisión y explicabilidad.

## Validación de la selección

Pruebas de rendimiento: Se realizaron pruebas comparativas de precisión entre Random Forest y XGBoost en dataset de validación. XGBoost mostró mayor precisión (AUC-ROC 0.85 versus 0.82 de Random Forest) en predicción de control glucémico. Ambos algoritmos mostraron tiempos de inferencia aceptables (menos de 100ms por predicción).

Pruebas de integración: Se probó integración de ambos algoritmos en el sistema de recomendación. Se verificó que las predicciones se integran correctamente en cálculo de metas nutricionales. Se verificó que el sistema funciona correctamente cuando solo uno de los algoritmos está disponible (fallback).

Resultado: La selección de Random Forest y XGBoost proporciona un sistema robusto, preciso y explicable para recomendaciones nutricionales personalizadas en diabetes tipo 2.

