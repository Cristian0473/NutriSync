# ðŸ§  Sistema de Aprendizaje Continuo

## ðŸ“‹ Resumen

Se ha implementado un sistema de **aprendizaje continuo** que permite a NutriSync aprender de resultados reales de pacientes **sin afectar el funcionamiento actual**. El sistema es completamente **opcional** y se puede activar/desactivar fÃ¡cilmente.

---

## âœ… CaracterÃ­sticas Implementadas

### 1. **Feedback Loop: Aprender de Resultados Reales**

El sistema captura y aprende de los resultados de los planes:

- **Registra baseline** cuando se crea un plan (HbA1c, glucosa, peso inicial)
- **Registra resultados** cuando el paciente completa el plan
- **Calcula si fue exitoso** basado en mejoras clÃ­nicas
- **Aprende patrones** de quÃ© ingredientes/combinaciones funcionaron

**Archivo**: `aprendizaje_continuo.py` â†’ mÃ©todos `registrar_resultado_plan()` y `actualizar_resultado_plan()`

### 2. **Memoria a Largo Plazo: Recordar quÃ© FuncionÃ³**

El sistema almacena patrones aprendidos:

- **Ingredientes exitosos**: QuÃ© ingredientes funcionaron mejor
- **Combinaciones efectivas**: QuÃ© combinaciones de alimentos dieron buenos resultados
- **Distribuciones Ã³ptimas**: QuÃ© distribuciÃ³n de macronutrientes fue mÃ¡s efectiva
- **Confianza**: Cada patrÃ³n tiene un nivel de confianza basado en frecuencia de Ã©xito

**Archivo**: `aprendizaje_continuo.py` â†’ mÃ©todos `_aprender_de_resultado()` y `_actualizar_patron_ingrediente()`

### 3. **Reentrenamiento AutomÃ¡tico: Actualizar Modelo PeriÃ³dicamente**

El sistema puede reentrenar el modelo ML automÃ¡ticamente:

- **Verifica** si hay suficientes datos nuevos (â‰¥50 resultados)
- **Inicia reentrenamiento** automÃ¡ticamente
- **Registra** versiones y mÃ©tricas del nuevo modelo
- **Compara** mejoras vs modelo anterior

**Archivo**: `aprendizaje_continuo.py` â†’ mÃ©todos `verificar_reentrenamiento_necesario()` y `iniciar_reentrenamiento()`

**Script**: `tarea_reentrenamiento.py` â†’ Ejecutar como tarea programada

### 4. **Aprendizaje por Refuerzo: Q-Learning**

El sistema usa Q-Learning para mejorar decisiones:

- **Aprende valores Q** de acciones (ajustar CHO, seleccionar ingrediente, etc.)
- **Actualiza valores** basado en recompensas (mejoras clÃ­nicas)
- **Recomienda mejores acciones** para estados similares

**Archivo**: `aprendizaje_continuo.py` â†’ mÃ©todos `obtener_mejor_accion()` y `actualizar_q_value()`

---

## ðŸš€ InstalaciÃ³n y ActivaciÃ³n

### Paso 1: Crear Tablas de Base de Datos

```bash
psql -U postgres -d proyecto_tesis -f SQL/aprendizaje_continuo.sql
```

### Paso 2: Activar Aprendizaje Continuo

Agregar al archivo `.env`:

```env
APRENDIZAJE_CONTINUO=true
```

O establecer variable de entorno:

```bash
# Windows
set APRENDIZAJE_CONTINUO=true

# Linux/Mac
export APRENDIZAJE_CONTINUO=true
```

### Paso 3: (Opcional) Configurar Tarea Programada para Reentrenamiento

**Windows (Task Scheduler)**:
- Crear tarea que ejecute: `python tarea_reentrenamiento.py`
- Programar para ejecutar semanalmente

**Linux/Mac (Cron)**:
```bash
# Ejecutar cada domingo a las 2 AM
0 2 * * 0 cd /ruta/al/proyecto && python tarea_reentrenamiento.py
```

---

## ðŸ”§ IntegraciÃ³n en el Sistema

### Hooks AutomÃ¡ticos

El sistema se integra automÃ¡ticamente sin modificar cÃ³digo existente:

1. **Cuando se guarda un plan** (`main.py` lÃ­nea ~220):
   - Se registra baseline automÃ¡ticamente
   - No afecta si falla (try/except silencioso)

2. **Cuando se completa un plan**:
   - Se actualizan resultados
   - Se aprende de patrones
   - Se actualizan valores Q

### Uso en Motor de RecomendaciÃ³n

El motor puede usar aprendizaje para mejorar selecciÃ³n:

```python
from aprendizaje_continuo import obtener_aprendizaje

aprendizaje = obtener_aprendizaje()

# Obtener ingredientes recomendados por aprendizaje
ingredientes_aprendidos = aprendizaje.obtener_ingredientes_recomendados_por_aprendizaje(
    paciente_id=paciente_id,
    grupo='GRUPO1_CEREALES',
    limite=5
)

# Si hay ingredientes aprendidos, usarlos en lugar de selecciÃ³n aleatoria
if ingredientes_aprendidos:
    # Usar ingredientes con alta confianza
    ingredientes = ingredientes_aprendidos
else:
    # Fallback a selecciÃ³n normal
    ingredientes = seleccion_normal()
```

---

## ðŸ“Š Estructura de Datos

### Tabla: `plan_resultado`

Almacena resultados de planes seguidos:

- **Baseline**: Datos iniciales (HbA1c, glucosa, peso)
- **Resultado**: Datos finales despuÃ©s del plan
- **Feedback**: SatisfacciÃ³n, cumplimiento, recomendaciÃ³n

### Tabla: `aprendizaje_patron`

Almacena patrones aprendidos:

- **Tipo**: `ingrediente_exitoso`, `combinacion_efectiva`, `macronutriente_optimo`
- **Elemento**: ID y nombre del ingrediente/combinaciÃ³n
- **Confianza**: Porcentaje de Ã©xito (0-100%)
- **Frecuencia**: Veces observado y veces exitoso

### Tabla: `modelo_reentrenamiento`

Registra reentrenamientos:

- **Versiones**: VersiÃ³n anterior y nueva
- **MÃ©tricas**: Accuracy, AUC, F1 del nuevo modelo
- **Mejora**: ComparaciÃ³n con modelo anterior

### Tabla: `refuerzo_q_values`

Almacena valores Q de Q-Learning:

- **Estado**: Hash del estado del paciente
- **AcciÃ³n**: Tipo y valor de acciÃ³n tomada
- **Q-value**: Calidad aprendida de la acciÃ³n
- **Recompensa**: Recompensa recibida

---

## ðŸŽ¯ Flujo de Aprendizaje

```
1. Paciente recibe plan
   â†“
2. Sistema registra baseline (HbA1c, glucosa, peso inicial)
   â†“
3. Paciente sigue plan durante X dÃ­as
   â†“
4. Paciente vuelve con nuevos datos clÃ­nicos
   â†“
5. Sistema actualiza resultado del plan
   â†“
6. Sistema calcula si fue exitoso
   â†“
7. Sistema aprende patrones:
   - Ingredientes que funcionaron
   - Combinaciones efectivas
   - Distribuciones Ã³ptimas
   â†“
8. Sistema actualiza valores Q (aprendizaje por refuerzo)
   â†“
9. PrÃ³ximos planes usan conocimiento aprendido
   â†“
10. Cuando hay suficientes datos nuevos:
    - Sistema reentrena modelo ML
    - Mejora predicciones futuras
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

```env
# Activar/desactivar aprendizaje continuo
APRENDIZAJE_CONTINUO=true

# Umbral mÃ­nimo de confianza para usar ingredientes aprendidos
APRENDIZAJE_CONFIANZA_MINIMA=60.0

# MÃ­nimo de resultados nuevos para reentrenar
APRENDIZAJE_MIN_RESULTADOS=50
```

### ParÃ¡metros de Q-Learning

En `aprendizaje_continuo.py`:

```python
alpha = 0.1  # Tasa de aprendizaje (quÃ© tan rÃ¡pido aprende)
gamma = 0.9  # Factor de descuento (importancia de recompensas futuras)
```

---

## ðŸ“ˆ Monitoreo

### Consultar Patrones Aprendidos

```sql
-- Ingredientes mÃ¡s exitosos
SELECT elemento_nombre, confianza, veces_observado, veces_exitoso
FROM aprendizaje_patron
WHERE tipo_patron = 'ingrediente_exitoso'
ORDER BY confianza DESC
LIMIT 10;

-- Resultados de planes
SELECT 
    pr.plan_id,
    pr.hba1c_inicial,
    pr.hba1c_final,
    (pr.hba1c_inicial - pr.hba1c_final) as mejora_hba1c,
    pr.resultado_exitoso
FROM plan_resultado pr
WHERE pr.estado = 'completado'
ORDER BY pr.fecha_fin DESC;
```

### EstadÃ­sticas de Aprendizaje

```python
from aprendizaje_continuo import obtener_aprendizaje
from bd_conexion import fetch_one

aprendizaje = obtener_aprendizaje()

# Contar patrones aprendidos
patrones = fetch_one("SELECT COUNT(*) FROM aprendizaje_patron")
print(f"Patrones aprendidos: {patrones[0]}")

# Contar resultados registrados
resultados = fetch_one("SELECT COUNT(*) FROM plan_resultado WHERE estado='completado'")
print(f"Resultados registrados: {resultados[0]}")
```

---

## âš ï¸ Consideraciones

### 1. **No Afecta Funcionamiento Actual**

- Todos los hooks tienen `try/except` silencioso
- Si falla, el sistema continÃºa normalmente
- Se puede desactivar en cualquier momento

### 2. **Requiere Datos Reales**

- El aprendizaje solo funciona con resultados reales
- Necesita que los pacientes vuelvan con datos clÃ­nicos
- Al inicio, habrÃ¡ pocos datos aprendidos

### 3. **Reentrenamiento Requiere ImplementaciÃ³n**

- El script `tarea_reentrenamiento.py` tiene estructura bÃ¡sica
- Falta implementar lÃ³gica de reentrenamiento real
- Se puede usar el cÃ³digo de `ApartadoInteligente/Entrenamiento/`

### 4. **Privacidad y Ã‰tica**

- Los datos se almacenan en la misma BD
- Cumple con las mismas polÃ­ticas de privacidad
- Se puede agregar anonimizaciÃ³n si es necesario

---

## ðŸ”® Mejoras Futuras

1. **Dashboard de Aprendizaje**: Interfaz para ver quÃ© aprendiÃ³ el sistema
2. **A/B Testing**: Comparar planes con/sin aprendizaje
3. **Explicabilidad**: Mostrar por quÃ© se recomienda algo (basado en aprendizaje)
4. **Notificaciones**: Alertar cuando hay suficientes datos para reentrenar
5. **ExportaciÃ³n**: Exportar patrones aprendidos para anÃ¡lisis

---

## âœ… Checklist de ImplementaciÃ³n

- [x] Crear tablas de base de datos
- [x] Implementar mÃ³dulo de aprendizaje continuo
- [x] Integrar hooks en `main.py`
- [x] Crear script de reentrenamiento
- [x] DocumentaciÃ³n completa
- [ ] Implementar reentrenamiento real del modelo
- [ ] Crear dashboard de monitoreo
- [ ] Agregar tests unitarios
- [ ] Configurar tarea programada en producciÃ³n

---

## ðŸ“ž Uso

### Activar Aprendizaje

```bash
# 1. Crear tablas
psql -U postgres -d proyecto_tesis -f SQL/aprendizaje_continuo.sql

# 2. Activar en .env
echo "APRENDIZAJE_CONTINUO=true" >> .env

# 3. Reiniciar servidor
python iniciar_servidor.py
```

### Verificar Funcionamiento

```python
from aprendizaje_continuo import obtener_aprendizaje

aprendizaje = obtener_aprendizaje()
print(f"Aprendizaje habilitado: {aprendizaje.habilitado}")
```

### Ejecutar Reentrenamiento Manualmente

```bash
python tarea_reentrenamiento.py
```

---

## ðŸŽ‰ ConclusiÃ³n

El sistema de aprendizaje continuo estÃ¡ **completamente implementado** y **listo para usar**. Es **opcional**, **no afecta el funcionamiento actual**, y se puede activar cuando se tengan suficientes datos reales de pacientes.

**El sistema ahora puede aprender y mejorar continuamente** ðŸš€

