"""
Script para analizar el dataset procesado y evaluar si es suficiente para entrenar modelos.
"""
import pandas as pd
import json
from pathlib import Path

DATASETS_DIR = Path(__file__).parent / "Datasets"

# Cargar dataset
df = pd.read_csv(DATASETS_DIR / "nhanes_procesado.csv")

print("="*60)
print("AN√ÅLISIS DEL DATASET PROCESADO")
print("="*60)
print(f"\nTotal de filas: {len(df):,}")

# An√°lisis de completitud
print("\nüìä COMPLETITUD DE VARIABLES CLAVE:")
variables_clave = ['hba1c', 'glucosa_ayunas', 'peso', 'talla', 'imc', 'ldl', 'hdl', 'trigliceridos']
for var in variables_clave:
    if var in df.columns:
        completos = df[var].notna().sum()
        porcentaje = (completos / len(df)) * 100
        print(f"  - {var:20s}: {completos:4d} valores ({porcentaje:5.1f}%)")

# An√°lisis de criterios DM2
print("\nüîç AN√ÅLISIS DE CRITERIOS DM2:")
if 'hba1c' in df.columns:
    hba1c_dm2 = (df['hba1c'] >= 6.5).sum()
    hba1c_prediabetes = ((df['hba1c'] >= 5.7) & (df['hba1c'] < 6.5)).sum()
    print(f"  - HbA1c ‚â• 6.5 (DM2): {hba1c_dm2} pacientes")
    print(f"  - HbA1c 5.7-6.4 (Prediabetes): {hba1c_prediabetes} pacientes")

if 'glucosa_ayunas' in df.columns:
    glu_dm2 = (df['glucosa_ayunas'] >= 126).sum()
    glu_prediabetes = ((df['glucosa_ayunas'] >= 100) & (df['glucosa_ayunas'] < 126)).sum()
    print(f"  - Glucosa ‚â• 126 (DM2): {glu_dm2} pacientes")
    print(f"  - Glucosa 100-125 (Prediabetes): {glu_prediabetes} pacientes")

# Evaluaci√≥n de tama√±o para ML
print("\nüìà EVALUACI√ìN PARA MACHINE LEARNING:")
print(f"  - Dataset actual: {len(df):,} filas")
print(f"  - Recomendado m√≠nimo para Random Forest: 1,000-5,000 filas")
print(f"  - Recomendado m√≠nimo para XGBoost: 1,000-10,000 filas")
print(f"  - Recomendado para modelos complejos: 5,000+ filas")

# An√°lisis de balance de clases
print("\n‚öñÔ∏è  BALANCE DE CLASES (Targets para ML):")
if 'control_glucemico' in df.columns:
    control_bien = (df['control_glucemico'] == 0).sum()
    control_mal = (df['control_glucemico'] == 1).sum()
    total_control = control_bien + control_mal
    if total_control > 0:
        print(f"  - Control gluc√©mico BUENO (HbA1c < 7.0): {control_bien} ({control_bien/total_control*100:.1f}%)")
        print(f"  - Control gluc√©mico MALO (HbA1c ‚â• 7.0): {control_mal} ({control_mal/total_control*100:.1f}%)")
        ratio = min(control_bien, control_mal) / max(control_bien, control_mal) if max(control_bien, control_mal) > 0 else 0
        if ratio > 0.7:
            print(f"  ‚úÖ Clases balanceadas (ratio: {ratio:.2f})")
        elif ratio > 0.5:
            print(f"  ‚ö†Ô∏è  Clases ligeramente desbalanceadas (ratio: {ratio:.2f})")
        else:
            print(f"  ‚ùå Clases muy desbalanceadas (ratio: {ratio:.2f}) - considerar SMOTE")

if 'riesgo_metabolico' in df.columns:
    riesgo_bajo = (df['riesgo_metabolico'] < 0.3).sum()
    riesgo_medio = ((df['riesgo_metabolico'] >= 0.3) & (df['riesgo_metabolico'] < 0.7)).sum()
    riesgo_alto = (df['riesgo_metabolico'] >= 0.7).sum()
    total_riesgo = riesgo_bajo + riesgo_medio + riesgo_alto
    if total_riesgo > 0:
        print(f"\n  - Riesgo metab√≥lico BAJO (<0.3): {riesgo_bajo} ({riesgo_bajo/total_riesgo*100:.1f}%)")
        print(f"  - Riesgo metab√≥lico MEDIO (0.3-0.7): {riesgo_medio} ({riesgo_medio/total_riesgo*100:.1f}%)")
        print(f"  - Riesgo metab√≥lico ALTO (‚â•0.7): {riesgo_alto} ({riesgo_alto/total_riesgo*100:.1f}%)")

# Evaluaci√≥n de tama√±o para ML
print("\nüìà EVALUACI√ìN PARA MACHINE LEARNING:")
print(f"  - Dataset actual: {len(df):,} filas")
print(f"  - Recomendado m√≠nimo para Random Forest: 1,000-5,000 filas")
print(f"  - Recomendado m√≠nimo para XGBoost: 1,000-10,000 filas")
print(f"  - Recomendado para modelos complejos: 5,000+ filas")

if len(df) >= 1000 and len(df) < 5000:
    print("\n‚úÖ DATASET ADECUADO para entrenar modelos:")
    print("   - Random Forest: ‚úÖ √ìptimo")
    print("   - XGBoost: ‚úÖ Aceptable (con regularizaci√≥n)")
    print("   - Logistic Regression: ‚úÖ Excelente")
    print("\nüìã PR√ìXIMOS PASOS:")
    print("   1. Preparar features y targets")
    print("   2. Dividir en train/validation/test (70/15/15)")
    print("   3. Entrenar Logistic Regression (baseline)")
    print("   4. Entrenar Random Forest (con regularizaci√≥n)")
    print("   5. Entrenar XGBoost (si Random Forest funciona bien)")
    print("   6. Comparar modelos y seleccionar el mejor")
elif len(df) < 1000:
    print("\n‚ö†Ô∏è  ADVERTENCIA: Dataset peque√±o para modelos complejos")
    print("   Recomendaciones:")
    print("   1. Incluir prediabetes (HbA1c 5.7-6.4 o GLU 100-125)")
    print("   2. Relajar umbral de faltantes (de 30% a 50%)")
    print("   3. Usar t√©cnicas para datasets peque√±os:")
    print("      - Validaci√≥n cruzada estratificada")
    print("      - Regularizaci√≥n fuerte")
    print("      - Modelos m√°s simples (Logistic Regression primero)")
    print("      - Data augmentation sint√©tica")
else:
    print("\n‚úÖ DATASET EXCELENTE para entrenar modelos complejos")
    print("   - Todos los modelos son viables")
    print("   - Puedes usar t√©cnicas avanzadas sin restricciones")

